# Implémentation d'un agent de réflexion avec LangGraph

Dans ce document, nous allons examiner comment implémenter un agent de réflexion en utilisant LangGraph, un outil puissant pour créer des flux de travail basés sur des modèles de langage.

# Implementation of a reflection agent with LangGraph

*In this document, we will examine how to implement a reflection agent using LangGraph, a powerful tool for creating language model-based workflows.*

---

# Exécution et analyse du graphe

Lançons notre code. Le graphe entre maintenant en phase d'exécution.

Si nous nous rendons sur LangSmith et accédons à notre projet d'agent de réflexion, nous pouvons constater qu'une trace est en cours d'exécution. Attendons que celle-ci se termine puis ouvrons-la pour analyse.

Première observation : l'exécution a pris près de 20 secondes. Cette durée s'explique par les nombreux appels API effectués vers le modèle de langage (LLM). 

En examinant le prompt final envoyé au LLM, nous pouvons visualiser le résultat obtenu : le tweet définitif après l'ensemble du processus de réflexion.

# Running and analyzing the graph

*Let's run our code. The graph is now executing.*

*If we go to LangSmith and access our reflection agent project, we can see we have a trace which is still running. Let's wait until it finishes and then open this trace for analysis.*

*First observation: it took almost 20 seconds to run. This duration makes sense because we made numerous API calls to the language model (LLM).*

*By examining the final prompt sent to the LLM, we can visualize the obtained result: the definitive tweet after the entire reflection process.*

---

# Analyse du processus

Pour mieux comprendre la démarche et le travail effectué par le LLM, analysons le prompt final qui contient tout l'historique et l'ensemble des interactions de l'agent avec le modèle.

Nous observons d'abord un message système initial indiquant : "Vous êtes un assistant influenceur technique sur Twitter chargé de rédiger d'excellents posts Twitter...". Puis vient notre instruction : "Améliore ce tweet".

C'est alors que commence l'itération du graphe. La première étape consiste à générer une révision du tweet via le nœud "generate" (génération). Comme nous n'avons pas terminé nos itérations, nous passons au nœud "reflect" (réflexion). La réponse renvoyée par le LLM, artificiellement étiquetée ici comme "human" (humain), fournit des commentaires critiques sur ce tweet.

# Process analysis

*To better understand the approach and the work done by the LLM, let's analyze the final prompt which contains all the history and interactions of the agent with the model.*

*We first observe an initial system message stating: "You are a technical Twitter influencer tasked with writing excellent Twitter posts...". Then comes our instruction: "Make this tweet better".*

*This is when the graph iteration begins. The first step consists of generating a revision of the tweet via the "generate" node. Since we haven't finished our iterations, we move to the "reflect" node. The response returned by the LLM, artificially tagged here as "human", provides critical feedback about this tweet.*

---

# Cycle d'amélioration

Une fois ce nœud terminé, nous retournons au nœud "generate" pour produire un nouveau tweet en tenant compte de ces commentaires. Ce cycle se poursuit jusqu'à l'obtention du résultat final.

Sur le côté gauche de l'interface, nous pouvons remarquer que LangChain offre une traçabilité et une observabilité complètes pour les objets LangGraph. Nous visualisons la fonction "should_continue" (devrait continuer), les nœuds de réflexion, et tous nos objets LangGraph intégrés dans la trace d'exécution.

# Improvement cycle

*Once this node is completed, we return to the "generate" node to produce a new tweet taking into account this feedback. This cycle continues until the final result is obtained.*

*On the left side of the interface, we can notice that LangChain provides complete traceability and observability for LangGraph objects. We visualize the "should_continue" function, the reflection nodes, and all our LangGraph objects built into the execution trace.*

---

# Conclusion

Nous avons ainsi implémenté une version simplifiée d'un algorithme de critique utilisant LangGraph. Cette implémentation aurait été possible avec LangChain seul, mais l'utilisation de LangGraph a considérablement simplifié le processus.

# Conclusion

*We have thus implemented a simplified version of a critiquing algorithm using LangGraph. This implementation would have been possible with LangChain alone, but using LangGraph has considerably simplified the process.*

---

# Tableau de vocabulaire technique

| Français | Anglais |
|----------|---------|
| graphe | graph |
| nœud | node |
| trace d'exécution | execution trace |
| modèle de langage (LLM) | language model (LLM) |
| agent de réflexion | reflection agent |
| prompt | prompt |
| itération | iteration |
| génération | generate |
| réflexion | reflect |
| traçabilité | traceability |
| observabilité | observability |
| fonction "devrait continuer" | "should_continue" function |
| flux de travail | workflow |
| appels API | API calls |