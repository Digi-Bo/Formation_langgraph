# Implémentation d'un Agent Acteur avec LangChain et LangGraph

## Introduction

Ce tutoriel explique comment implémenter un agent acteur (actor agent) dans le cadre d'un système d'intelligence artificielle. Nous allons construire ce qu'on appelle une "first responder chain" (chaîne de premier répondant), qui sera la première étape de notre graphe. Cette chaîne prendra en entrée la requête de l'utilisateur et générera un article initial.

Nous allons couvrir plusieurs techniques avancées de prompting et utiliser des output parsers (analyseurs de sortie), en particulier le function calling (appel de fonction) pour obtenir une sortie structurée.

## Préparation et importations

Commençons par les importations nécessaires :

```python
import datetime
from dotenv import load_dotenv

load_dotenv()

from langchain_core.output_parsers.openai_tools import (
    JsonOutputToolsParser,
    PydanticToolsParser,
)
from langchain_core.messages import HumanMessage
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_openai import ChatOpenAI

from schemas import AnswerQuestion
```

Nous importons :
- `datetime` pour passer la date et l'heure actuelles à notre agent
- `load_dotenv` pour charger les variables d'environnement depuis notre fichier `.env`
- Les parseurs de sortie `JsonOutputToolsParser` et `PydanticToolsParser` qui vont traiter la réponse obtenue via function calling
- `HumanMessage` pour passer des messages à notre LLM
- `ChatPromptTemplate` et `MessagesPlaceholder` pour gérer l'historique des interactions
- `ChatOpenAI` pour utiliser GPT-4 Turbo

## Définition des schémas de sortie

Pour structurer la sortie de notre LLM, nous allons définir des schémas Pydantic. Créons un fichier `schemas.py` :

```python
from typing import List
from pydantic import BaseModel, Field

class Reflection(BaseModel):
    missing: str = Field(description="Critique of what is missing.")
    superfluous: str = Field(description="Critique of what is superfluous")

class AnswerQuestion(BaseModel):
    """Answer the question."""
    
    answer: str = Field(description="~250 word detailed answer to the question.")
    reflection: Reflection = Field(description="Your reflection on the initial answer.")
    search_queries: List[str] = Field(
        description="1-3 search queries for researching improvements to address the critique of your current answer."
    )
```

Ces classes définissent la structure de sortie attendue :
- `Reflection` : contient deux champs pour la critique - les informations manquantes et les informations superflues
- `AnswerQuestion` : classe principale comportant trois champs :
  - `answer` : une réponse détaillée de 250 mots à la question initiale
  - `reflection` : un objet de type `Reflection` avec la critique de la réponse
  - `search_queries` : une liste de requêtes de recherche pour améliorer la réponse

Un aspect intéressant est que nous utilisons les descriptions des champs pour guider le LLM dans la génération du contenu approprié.

## Création du prompt principal

Définissons maintenant le prompt principal qui sera utilisé par notre agent :

```python
llm = ChatOpenAI(model="o4-mini")
parser = JsonOutputToolsParser(return_id=True)
parser_pydantic = PydanticToolsParser(tools=[AnswerQuestion])

actor_prompt_template = ChatPromptTemplate.from_messages(
    [
        (
            "system",
            """You are expert researcher.
Current time: {time}

1. {first_instruction}
2. Reflect and critique your answer. Be severe to maximize improvement.
3. Recommend search queries to research information and improve your answer.""",
        ),
        MessagesPlaceholder(variable_name="messages"),
        ("system", "Answer the user's question above using the required format."),
    ]
).partial(
    time=lambda: datetime.datetime.now().isoformat(),
)
```

Notre prompt contient :
- Un message système qui définit le rôle de l'agent (expert chercheur)
- L'heure actuelle (injectée dynamiquement)
- Trois instructions :
  1. Une instruction principale (qui sera définie plus tard)
  2. Une demande de réflexion et critique de la réponse
  3. Une demande de recommandation de requêtes de recherche

Nous utilisons également un `MessagesPlaceholder` pour stocker l'historique des messages, ce qui sera utile plus tard dans l'agent de révision (revisor agent).

## Configuration de la chaîne de premier répondant

Configurons maintenant notre chaîne de premier répondant :

```python
first_responder_prompt_template = actor_prompt_template.partial(
    first_instruction="Provide a detailed ~250 word answer."
)

first_responder = first_responder_prompt_template | llm.bind_tools(
    tools=[AnswerQuestion], tool_choice="AnswerQuestion"
)
```

Nous complétons notre prompt avec l'instruction spécifique pour le premier répondant : "Fournir une réponse détaillée d'environ 250 mots". Ensuite, nous lions ce prompt à notre LLM en utilisant `bind_tools` pour forcer l'utilisation de notre class `AnswerQuestion` comme structure de sortie.

## Test de la chaîne

Testons notre chaîne avec un exemple concret :

```python
if __name__ == "__main__":
    human_message = HumanMessage(
        content="Write about AI-Powered SOC / autonomous soc problem domain,"
        " list startups that do that and raised capital."
    )
    chain = (
        first_responder_prompt_template
        | llm.bind_tools(tools=[AnswerQuestion], tool_choice="AnswerQuestion")
        | parser_pydantic
    )

    res = chain.invoke(input={"messages": [human_message]})
    print(res)
```

Nous créons un message demandant des informations sur les "AI-Powered SOC" (Security Operation Centers propulsés par l'IA), puis nous configurons et exécutons notre chaîne.

## Analyse des résultats

Après exécution, nous obtenons un objet `AnswerQuestion` structuré contenant :

1. La réponse principale (answer) : un texte d'environ 250 mots sur les SOC propulsés par l'IA
2. Une réflexion (reflection) avec :
   - Les informations manquantes : "La réponse pourrait bénéficier de données plus précises sur le montant des capitaux levés par chaque startup mentionnée"
   - Les informations superflues : "L'explication détaillée du problème pourrait être légèrement redondante pour les lecteurs déjà familiers avec le concept"
3. Des requêtes de recherche pour améliorer la réponse, comme "AI powered SOC startup funding"

## Avantages de cette approche

Cette implémentation présente plusieurs avantages :

1. **Sortie structurée** : Nous obtenons une réponse bien organisée grâce à l'utilisation de function calling
2. **Auto-critique** : L'agent évalue sa propre réponse et identifie les points d'amélioration
3. **Recherche guidée** : L'agent suggère des requêtes de recherche spécifiques pour enrichir la réponse

## Prochaines étapes

Dans le processus complet, cette première réponse sera ensuite améliorée par :
1. L'exécution des requêtes de recherche à l'aide d'un moteur comme Tavily
2. L'utilisation d'un agent de révision (revisor agent) qui prendra en compte les résultats de recherche pour produire une version améliorée de l'article

## Conclusion

Nous avons implémenté avec succès un agent acteur (actor agent) capable de générer une première réponse structurée à une requête. Cette réponse inclut non seulement le contenu principal, mais aussi une auto-critique et des suggestions de recherche pour amélioration.

Les techniques avancées de prompting et l'utilisation de function calling nous permettent d'obtenir exactement le format de sortie souhaité, rendant l'agent plus prévisible et efficace.