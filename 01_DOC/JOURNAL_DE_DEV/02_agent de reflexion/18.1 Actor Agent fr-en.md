# Implémentation d'un Agent Acteur avec LangChain et LangGraph

## Introduction

# ** Introduction**
Ce tutoriel explique comment implémenter un agent acteur (actor agent) dans le cadre d'un système d'intelligence artificielle. Nous allons construire ce qu'on appelle une "first responder chain" (chaîne de premier répondant), qui sera la première étape de notre graphe. Cette chaîne prendra en entrée la requête de l'utilisateur et générera un article initial.

Nous allons couvrir plusieurs techniques avancées de prompting et utiliser des output parsers (analyseurs de sortie), en particulier le function calling (appel de fonction) pour obtenir une sortie structurée.

# ** Introduction**
*This tutorial explains how to implement an actor agent in an artificial intelligence system. We will build what is called a "first responder chain", which will be the first step of our graph. This chain will take the user's query as input and generate an initial article.*

*We will cover several advanced prompting techniques and use output parsers, particularly function calling to obtain structured output.*

---

# ** Préparation et importations**
Commençons par les importations nécessaires :

```python
import datetime
from dotenv import load_dotenv

load_dotenv()

from langchain_core.output_parsers.openai_tools import (
    JsonOutputToolsParser,
    PydanticToolsParser,
)
from langchain_core.messages import HumanMessage
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_openai import ChatOpenAI

from schemas import AnswerQuestion
```

Nous importons :
- `datetime` pour passer la date et l'heure actuelles à notre agent
- `load_dotenv` pour charger les variables d'environnement depuis notre fichier `.env`
- Les parseurs de sortie `JsonOutputToolsParser` et `PydanticToolsParser` qui vont traiter la réponse obtenue via function calling
- `HumanMessage` pour passer des messages à notre LLM
- `ChatPromptTemplate` et `MessagesPlaceholder` pour gérer l'historique des interactions
- `ChatOpenAI` pour utiliser GPT-4 Turbo

# ** Preparation and imports**
*Let's start with the necessary imports:*

```python
import datetime
from dotenv import load_dotenv

load_dotenv()

from langchain_core.output_parsers.openai_tools import (
    JsonOutputToolsParser,
    PydanticToolsParser,
)
from langchain_core.messages import HumanMessage
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_openai import ChatOpenAI

from schemas import AnswerQuestion
```

*We import:*
- *`datetime` to pass the current date and time to our agent*
- *`load_dotenv` to load environment variables from our `.env` file*
- *The output parsers `JsonOutputToolsParser` and `PydanticToolsParser` that will process the response obtained via function calling*
- *`HumanMessage` to pass messages to our LLM*
- *`ChatPromptTemplate` and `MessagesPlaceholder` to manage interaction history*
- *`ChatOpenAI` to use GPT-4 Turbo*

---




# ** Les schémas Pydantic**
Les schémas Pydantic sont des modèles de données en Python qui permettent de définir et valider des structures de données complexes. Ils combinent la vérification des types à l'exécution avec la validation des données selon des règles personnalisables. Dans le contexte des LLMs, ils servent à structurer les réponses en définissant les champs attendus, leurs types et formats. Les attributs `Field` permettent d'ajouter des métadonnées comme des descriptions qui guident le LLM dans la génération de contenu. Pydantic transforme automatiquement les données brutes (JSON) en objets Python exploitables et signale les erreurs si les données ne respectent pas le schéma défini.

# ** Pydantic schemas**
*Pydantic schemas are data models in Python that allow defining and validating complex data structures. They combine runtime type checking with data validation according to customizable rules. In the LLM context, they help structure responses by defining expected fields, their types, and formats. The `Field` attributes add metadata such as descriptions that guide the LLM in content generation. Pydantic automatically transforms raw data (JSON) into usable Python objects and raises errors if the data doesn't comply with the defined schema.*



---


# ** Définition des schémas de sortie**
Pour structurer la sortie de notre LLM, nous allons définir des schémas Pydantic. Créons un fichier `schemas.py` :

```python
from typing import List
from pydantic import BaseModel, Field

class Reflection(BaseModel):
    missing: str = Field(description="Critique of what is missing.")
    superfluous: str = Field(description="Critique of what is superfluous")

class AnswerQuestion(BaseModel):
    """Answer the question."""
    
    answer: str = Field(description="~250 word detailed answer to the question.")
    reflection: Reflection = Field(description="Your reflection on the initial answer.")
    search_queries: List[str] = Field(
        description="1-3 search queries for researching improvements to address the critique of your current answer."
    )
```

Ces classes définissent la structure de sortie attendue :
- `Reflection` : contient deux champs pour la critique - les informations manquantes et les informations superflues
- `AnswerQuestion` : classe principale comportant trois champs :
  - `answer` : une réponse détaillée de 250 mots à la question initiale
  - `reflection` : un objet de type `Reflection` avec la critique de la réponse
  - `search_queries` : une liste de requêtes de recherche pour améliorer la réponse

Un aspect intéressant est que nous utilisons les descriptions des champs pour guider le LLM dans la génération du contenu approprié.

# ** Definition of output schemas**
*To structure the output of our LLM, we will define Pydantic schemas. Let's create a `schemas.py` file:*

```python
from typing import List
from pydantic import BaseModel, Field

class Reflection(BaseModel):
    missing: str = Field(description="Critique of what is missing.")
    superfluous: str = Field(description="Critique of what is superfluous")

class AnswerQuestion(BaseModel):
    """Answer the question."""
    
    answer: str = Field(description="~250 word detailed answer to the question.")
    reflection: Reflection = Field(description="Your reflection on the initial answer.")
    search_queries: List[str] = Field(
        description="1-3 search queries for researching improvements to address the critique of your current answer."
    )
```

*These classes define the expected output structure:*
- *`Reflection`: contains two fields for criticism - missing information and superfluous information*
- *`AnswerQuestion`: main class with three fields:*
  - *`answer`: a detailed 250-word answer to the initial question*
  - *`reflection`: an object of type `Reflection` with criticism of the answer*
  - *`search_queries`: a list of search queries to improve the answer*

*An interesting aspect is that we use field descriptions to guide the LLM in generating appropriate content.*

---

# ** Création du prompt principal**
Définissons maintenant le prompt principal qui sera utilisé par notre agent :

```python
llm = ChatOpenAI(model="o4-mini")
parser = JsonOutputToolsParser(return_id=True)
parser_pydantic = PydanticToolsParser(tools=[AnswerQuestion])

actor_prompt_template = ChatPromptTemplate.from_messages(
    [
        (
            "system",
            """You are expert researcher.
Current time: {time}

1. {first_instruction}
2. Reflect and critique your answer. Be severe to maximize improvement.
3. Recommend search queries to research information and improve your answer.""",
        ),
        MessagesPlaceholder(variable_name="messages"),
        ("system", "Answer the user's question above using the required format."),
    ]
).partial(
    time=lambda: datetime.datetime.now().isoformat(),
)
```

Notre prompt contient :
- Un message système qui définit le rôle de l'agent (expert chercheur)
- L'heure actuelle (injectée dynamiquement)
- Trois instructions :
  1. Une instruction principale (qui sera définie plus tard)
  2. Une demande de réflexion et critique de la réponse
  3. Une demande de recommandation de requêtes de recherche

Nous utilisons également un `MessagesPlaceholder` pour stocker l'historique des messages, ce qui sera utile plus tard dans l'agent de révision (revisor agent).

# ** Creation of the main prompt**
*Let's now define the main prompt that will be used by our agent:*

```python
llm = ChatOpenAI(model="o4-mini")
parser = JsonOutputToolsParser(return_id=True)
parser_pydantic = PydanticToolsParser(tools=[AnswerQuestion])

actor_prompt_template = ChatPromptTemplate.from_messages(
    [
        (
            "system",
            """You are expert researcher.
Current time: {time}

1. {first_instruction}
2. Reflect and critique your answer. Be severe to maximize improvement.
3. Recommend search queries to research information and improve your answer.""",
        ),
        MessagesPlaceholder(variable_name="messages"),
        ("system", "Answer the user's question above using the required format."),
    ]
).partial(
    time=lambda: datetime.datetime.now().isoformat(),
)
```

*Our prompt contains:*
- *A system message that defines the agent's role (expert researcher)*
- *The current time (dynamically injected)*
- *Three instructions:*
  1. *A main instruction (which will be defined later)*
  2. *A request for reflection and criticism of the answer*
  3. *A request for recommended search queries*

*We also use a `MessagesPlaceholder` to store the message history, which will be useful later in the revisor agent.*

---

# ** Configuration de la chaîne de premier répondant**
Configurons maintenant notre chaîne de premier répondant :

```python
first_responder_prompt_template = actor_prompt_template.partial(
    first_instruction="Provide a detailed ~250 word answer."
)

first_responder = first_responder_prompt_template | llm.bind_tools(
    tools=[AnswerQuestion], tool_choice="AnswerQuestion"
)
```

Nous complétons notre prompt avec l'instruction spécifique pour le premier répondant : "Fournir une réponse détaillée d'environ 250 mots". Ensuite, nous lions ce prompt à notre LLM en utilisant `bind_tools` pour forcer l'utilisation de notre class `AnswerQuestion` comme structure de sortie.

# ** Configuration of the first responder chain**
*Let's now configure our first responder chain:*

```python
first_responder_prompt_template = actor_prompt_template.partial(
    first_instruction="Provide a detailed ~250 word answer."
)

first_responder = first_responder_prompt_template | llm.bind_tools(
    tools=[AnswerQuestion], tool_choice="AnswerQuestion"
)
```

*We complete our prompt with the specific instruction for the first responder: "Provide a detailed ~250 word answer." Then, we bind this prompt to our LLM using `bind_tools` to force the use of our `AnswerQuestion` class as the output structure.*

---

# ** Test de la chaîne**
Testons notre chaîne avec un exemple concret :

```python
if __name__ == "__main__":
    human_message = HumanMessage(
        content="Write about AI-Powered SOC / autonomous soc problem domain,"
        " list startups that do that and raised capital."
    )
    chain = (
        first_responder_prompt_template
        | llm.bind_tools(tools=[AnswerQuestion], tool_choice="AnswerQuestion")
        | parser_pydantic
    )

    res = chain.invoke(input={"messages": [human_message]})
    print(res)
```

Nous créons un message demandant des informations sur les "AI-Powered SOC" (Security Operation Centers propulsés par l'IA), puis nous configurons et exécutons notre chaîne.

# ** Testing the chain**
*Let's test our chain with a concrete example:*

```python
if __name__ == "__main__":
    human_message = HumanMessage(
        content="Write about AI-Powered SOC / autonomous soc problem domain,"
        " list startups that do that and raised capital."
    )
    chain = (
        first_responder_prompt_template
        | llm.bind_tools(tools=[AnswerQuestion], tool_choice="AnswerQuestion")
        | parser_pydantic
    )

    res = chain.invoke(input={"messages": [human_message]})
    print(res)
```

*We create a message requesting information about "AI-Powered SOC" (Security Operation Centers powered by AI), then we configure and run our chain.*

---

# ** Analyse des résultats**
Après exécution, nous obtenons un objet `AnswerQuestion` structuré contenant :

1. La réponse principale (answer) : un texte d'environ 250 mots sur les SOC propulsés par l'IA
2. Une réflexion (reflection) avec :
   - Les informations manquantes : "La réponse pourrait bénéficier de données plus précises sur le montant des capitaux levés par chaque startup mentionnée"
   - Les informations superflues : "L'explication détaillée du problème pourrait être légèrement redondante pour les lecteurs déjà familiers avec le concept"
3. Des requêtes de recherche pour améliorer la réponse, comme "AI powered SOC startup funding"

# ** Results analysis**
*After execution, we obtain a structured `AnswerQuestion` object containing:*

1. *The main answer: a text of about 250 words on AI-powered SOCs*
2. *A reflection with:*
   - *Missing information: "The answer could benefit from more precise data on the amount of capital raised by each mentioned startup"*
   - *Superfluous information: "The detailed explanation of the problem might be slightly redundant for readers already familiar with the concept"*
3. *Search queries to improve the answer, such as "AI powered SOC startup funding"*

---

# ** Avantages de cette approche**
Cette implémentation présente plusieurs avantages :

1. **Sortie structurée** : Nous obtenons une réponse bien organisée grâce à l'utilisation de function calling
2. **Auto-critique** : L'agent évalue sa propre réponse et identifie les points d'amélioration
3. **Recherche guidée** : L'agent suggère des requêtes de recherche spécifiques pour enrichir la réponse

# ** Advantages of this approach**
*This implementation has several advantages:*

1. *__Structured output__: We obtain a well-organized response thanks to the use of function calling*
2. *__Self-criticism__: The agent evaluates its own response and identifies areas for improvement*
3. *__Guided research__: The agent suggests specific search queries to enrich the response*

---

# ** Prochaines étapes**
Dans le processus complet, cette première réponse sera ensuite améliorée par :
1. L'exécution des requêtes de recherche à l'aide d'un moteur comme Tavily
2. L'utilisation d'un agent de révision (revisor agent) qui prendra en compte les résultats de recherche pour produire une version améliorée de l'article

# ** Next steps**
*In the complete process, this first response will then be improved by:*
1. *Executing search queries using an engine like Tavily*
2. *Using a revisor agent that will take into account the search results to produce an improved version of the article*

---

# ** Conclusion**
Nous avons implémenté avec succès un agent acteur (actor agent) capable de générer une première réponse structurée à une requête. Cette réponse inclut non seulement le contenu principal, mais aussi une auto-critique et des suggestions de recherche pour amélioration.

Les techniques avancées de prompting et l'utilisation de function calling nous permettent d'obtenir exactement le format de sortie souhaité, rendant l'agent plus prévisible et efficace.

# ** Conclusion**
*We have successfully implemented an actor agent capable of generating a first structured response to a query. This response includes not only the main content, but also self-criticism and search suggestions for improvement.*

*Advanced prompting techniques and the use of function calling allow us to obtain exactly the desired output format, making the agent more predictable and efficient.*

---

## Tableau récapitulatif du lexique

| Français | Anglais |
|----------|---------|
| agent acteur | actor agent |
| chaîne de premier répondant | first responder chain |
| analyseurs de sortie | output parsers |
| appel de fonction | function calling |
| LLM (modèle de langage large) | LLM (Large Language Model) |
| schémas Pydantic | Pydantic schemas |
| auto-critique | self-criticism |
| prompt | prompt |
| agent de révision | revisor agent |
| sortie structurée | structured output |
| requête de recherche | search query |
| historique des messages | message history |
| variables d'environnement | environment variables |